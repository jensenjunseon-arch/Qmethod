"""
Step 6: Dual-Type Generation Module (ìœ í˜•ì˜ ì´ì›í™”)
ê° Factorì— ëŒ€í•´ ê¸ì • í¸í–¥ ìœ í˜•ê³¼ ë¶€ì • í¸í–¥ ìœ í˜•ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
from utils.llm_client import generate_json
from modules.factor_analysis import get_factor_interpretation_data


def generate_dual_types(
    factor_scores: pd.DataFrame,
    q_set: list[str],
    topic_info: dict,
    significant_loadings: dict
) -> list[dict]:
    """
    ê° Factorì— ëŒ€í•´ ê¸ì •/ë¶€ì • ì´ì›í™” ìœ í˜•ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        factor_scores: ìš”ì¸ë³„ ë¬¸í•­ Z-score DataFrame
        q_set: Q-Set ë¬¸í•­ ë¦¬ìŠ¤íŠ¸
        topic_info: ì—°êµ¬ ì£¼ì œ ì •ë³´
        significant_loadings: ìš”ì¸ë³„ ìœ ì˜ë¯¸í•œ ì°¸ì—¬ì ì •ë³´
    
    Returns:
        ìƒì„±ëœ ìœ í˜• ë¦¬ìŠ¤íŠ¸
    """
    print("\n" + "="*60)
    print("ğŸ”€ ìœ í˜• ì´ì›í™” (Dual-Type Generation)")
    print("="*60)
    
    interpretation_data = get_factor_interpretation_data(factor_scores, q_set, top_n=7)
    all_types = []
    
    for factor_name, data in interpretation_data.items():
        print(f"\nğŸ“Œ {factor_name} ì´ì›í™” ì¤‘...")
        
        # ê¸ì • í¸í–¥ ìœ í˜• ìƒì„±
        positive_type = generate_type(
            factor_name=factor_name,
            bias="positive",
            key_items=data["top_items"],
            topic_info=topic_info,
            significant_participants=[
                p for p in significant_loadings.get(factor_name, [])
                if p["direction"] == "positive"
            ]
        )
        positive_type["factor"] = factor_name
        positive_type["bias"] = "positive"
        positive_type["key_statements"] = data["top_items"]
        all_types.append(positive_type)
        print(f"   âœ… {positive_type.get('type_name', 'N/A')} (ê¸ì •)")
        
        # ë¶€ì • í¸í–¥ ìœ í˜• ìƒì„±
        negative_type = generate_type(
            factor_name=factor_name,
            bias="negative",
            key_items=data["bottom_items"],
            topic_info=topic_info,
            significant_participants=[
                p for p in significant_loadings.get(factor_name, [])
                if p["direction"] == "negative"
            ]
        )
        negative_type["factor"] = factor_name
        negative_type["bias"] = "negative"
        negative_type["key_statements"] = data["bottom_items"]
        all_types.append(negative_type)
        print(f"   âœ… {negative_type.get('type_name', 'N/A')} (ë¶€ì •)")
    
    print(f"\nğŸ“Š ì´ {len(all_types)}ê°œ ìœ í˜• ìƒì„± ì™„ë£Œ")
    
    return all_types


def generate_type(
    factor_name: str,
    bias: str,
    key_items: list[dict],
    topic_info: dict,
    significant_participants: list[dict]
) -> dict:
    """
    ë‹¨ì¼ ìœ í˜•ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        factor_name: ìš”ì¸ ì´ë¦„
        bias: "positive" ë˜ëŠ” "negative"
        key_items: í•µì‹¬ ë¬¸í•­ ë¦¬ìŠ¤íŠ¸
        topic_info: ì—°êµ¬ ì£¼ì œ ì •ë³´
        significant_participants: í•´ë‹¹ ìœ í˜•ì˜ ëŒ€í‘œ ì°¸ì—¬ìë“¤
    
    Returns:
        ìƒì„±ëœ ìœ í˜• ì •ë³´
    """
    bias_label = "ê¸ì • í¸í–¥" if bias == "positive" else "ë¶€ì • í¸í–¥"
    
    items_text = "\n".join([
        f"- {item['statement']} (Z-score: {item['z_score']:.2f})"
        for item in key_items
    ])
    
    participants_text = ""
    if significant_participants:
        participants_text = "ëŒ€í‘œ ì°¸ì—¬ì: " + ", ".join([
            f"{p['name']} (ì ì¬ëŸ‰: {p['loading']:.2f})"
            for p in significant_participants[:3]
        ])
    
    prompt = f"""
Që°©ë²•ë¡  ì—°êµ¬ì—ì„œ ë„ì¶œëœ ìœ í˜•ì„ ë¶„ì„í•˜ê³  ì„¤ëª…í•´ì£¼ì„¸ìš”.

## ì—°êµ¬ ì£¼ì œ
{topic_info.get('final_topic', '')}

## ìœ í˜• ì •ë³´
- ìš”ì¸: {factor_name}
- í¸í–¥: {bias_label}
{participants_text}

## í•µì‹¬ ë¬¸í•­ (Z-score ìˆœ)
{items_text}

## ìœ í˜• ëª…ëª… ê·œì¹™ (â˜… ë§¤ìš° ì¤‘ìš”)
1. **ë‹¤ë¥¸ ìœ í˜•ê³¼ ëª…í™•íˆ êµ¬ë¶„ë˜ëŠ” ì´ë¦„**: ë¹„ìŠ·í•œ ì´ë¦„ ê¸ˆì§€! ê° ìœ í˜•ì˜ ê°€ì¥ ë‘ë“œëŸ¬ì§„ íŠ¹ì§•ì„ ë‹´ì•„ì•¼ í•¨
2. **í˜•ì‹**: "ì •ì‹ ì´ë¦„ (Raw Voice)"
   - ì •ì‹ ì´ë¦„: í•™ìˆ ì ì´ê³  ì „ë¬¸ì ì¸ ëª…ì¹­ (4~8ì)
   - Raw Voice: ê·¸ ìœ í˜• ì‚¬ëŒì´ ì‹¤ì œë¡œ í•  ë²•í•œ í•œë§ˆë”” (5~15ì)
3. **ì˜ˆì‹œ**:
   - "ëƒ‰ì†Œì  ìƒì¡´ì£¼ì˜ì (ê²°êµ­ ì‚´ì•„ë‚¨ëŠ” ê²Œ ì´ê¸°ëŠ” ê±°ì•¼)"
   - "ì—´ì •ì  ê°€ì¹˜ì¶”êµ¬í˜• (ë‚´ ì‹ ë…ì€ íƒ€í˜‘ ëª» í•´)"
   - "ë¬´ê´€ì‹¬ ë°©ê´€ì (ë‚¨ ì¼ì— ê°ì • ìŸì§€ ë§ˆ)"
   - "í˜„ì‹¤ì£¼ì˜ ì ì‘ê°€ (ì•ˆ ë§ì•„ë„ ë§ì¶°ì•¼ì§€ ë­)"

## ìš”ì²­ì‚¬í•­
ì´ ìœ í˜•ì˜ íŠ¹ì„±ì„ ì‹¬ì¸µ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
íŠ¹íˆ 'ìƒì¡´ ë³¸ëŠ¥', 'ë°©ì–´ ê¸°ì œ', 'ìˆ¨ê²¨ì§„ ë‘ë ¤ì›€', 'ìê¸° ì •ë‹¹í™”' ë¶€ë¶„ì€ ë‚ ê²ƒ ê·¸ëŒ€ë¡œì˜ ì‹¬ë¦¬ë¥¼ íŒŒí—¤ì³ì£¼ì„¸ìš”.

{{
    "type_name": "ì •ì‹ ì´ë¦„ (Raw Voice í•œë§ˆë””)",
    "short_description": "15ë‹¨ì–´ ì´ë‚´ì˜ í•µì‹¬ íŠ¹ì§• ìš”ì•½ (ë‹¤ë¥¸ ìœ í˜•ê³¼ ì°¨ë³„ì  ê°•ì¡°)",
    "survival_instinct": "ì´ ìœ í˜•ì´ ë¬´ì˜ì‹ì ìœ¼ë¡œ ì¶”êµ¬í•˜ëŠ” ìƒì¡´ ì „ëµ. ì™œ ì´ëŸ° íƒœë„ë¥¼ ê°€ì§€ê²Œ ë˜ì—ˆëŠ”ì§€ ë³¸ëŠ¥ì  ê´€ì ì—ì„œ ë¶„ì„ (50ì ì´ìƒ)",
    "defense_mechanism": "ì´ ìœ í˜•ì´ ì‚¬ìš©í•˜ëŠ” ì‹¬ë¦¬ì  ë°©ì–´ ê¸°ì œ. ì–´ë–¤ ìƒí™©ì—ì„œ ì–´ë–»ê²Œ ìì‹ ì„ ë³´í˜¸í•˜ëŠ”ì§€ (50ì ì´ìƒ)",
    "hidden_fear": "ì´ ìœ í˜•ì´ ê²‰ìœ¼ë¡œ ë“œëŸ¬ë‚´ì§€ ì•Šì§€ë§Œ ë‚´ë©´ì— ê°€ì§„ ë‘ë ¤ì›€ê³¼ ë¶ˆì•ˆ (50ì ì´ìƒ)",
    "self_justification": "ì´ ìœ í˜•ì´ ìì‹ ì˜ íƒœë„ì™€ í–‰ë™ì„ ì •ë‹¹í™”í•˜ëŠ” ë‚´ë©´ì˜ ë…¼ë¦¬ì™€ ë§íˆ¬ (50ì ì´ìƒ)",
    "core_values": ["í•µì‹¬ê°€ì¹˜1", "í•µì‹¬ê°€ì¹˜2", "í•µì‹¬ê°€3"],
    "trigger_phrases": ["ì´ ìœ í˜•ì„ ìê·¹í•˜ëŠ” ë§1", "ìê·¹í•˜ëŠ” ë§2", "ìê·¹í•˜ëŠ” ë§3"],
    "action_plan": ["ì´ ìœ í˜•ì—ê²Œ íš¨ê³¼ì ì¸ ì ‘ê·¼ë²•1", "ì ‘ê·¼ë²•2", "ì ‘ê·¼ë²•3"]
}}
"""
    
    return generate_json(prompt, temperature=0.7)


def create_type_summary(types: list[dict]) -> str:
    """
    ëª¨ë“  ìœ í˜•ì˜ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        types: ìœ í˜• ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ìš”ì•½
    """
    summary = "# ìœ í˜• ìš”ì•½\n\n"
    
    for i, t in enumerate(types):
        bias_emoji = "â•" if t.get("bias") == "positive" else "â–"
        summary += f"""
## {i+1}. {t.get('type_name', f'ìœ í˜• {i+1}')} {bias_emoji}

**ìš”ì¸**: {t.get('factor', 'N/A')} | **í¸í–¥**: {"ê¸ì •" if t.get('bias') == 'positive' else "ë¶€ì •"}

**í•µì‹¬ íŠ¹ì§•**: {t.get('short_description', 'N/A')}

**ì‹¬ë¦¬ ë¶„ì„**: {t.get('psychology_analysis', 'N/A')}

**í•µì‹¬ ê°€ì¹˜**: {', '.join(t.get('core_values', []))}

---
"""
    
    return summary


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    test_factor_scores = pd.DataFrame({
        'Factor1': [1.5, 1.2, 0.8, -0.5, -1.0, -1.5],
        'Factor2': [-1.0, 0.5, 1.0, 1.5, -0.5, -1.2]
    }, index=['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6'])
    
    test_q_set = [
        "ë‚˜ëŠ” Aê°€ ì¤‘ìš”í•˜ë‹¤",
        "ë‚˜ëŠ” Bë¥¼ ì„ í˜¸í•œë‹¤",
        "ë‚˜ëŠ” Cë¥¼ ì¶”êµ¬í•œë‹¤",
        "ë‚˜ëŠ” Dê°€ í•„ìš”í•˜ë‹¤",
        "ë‚˜ëŠ” Eë¥¼ ì›í•œë‹¤",
        "ë‚˜ëŠ” Fë¥¼ ì§€ì§€í•œë‹¤"
    ]
    
    test_topic = {"final_topic": "í…ŒìŠ¤íŠ¸ ì£¼ì œ"}
    test_loadings = {"Factor1": [], "Factor2": []}
    
    types = generate_dual_types(test_factor_scores, test_q_set, test_topic, test_loadings)
    print(create_type_summary(types))
