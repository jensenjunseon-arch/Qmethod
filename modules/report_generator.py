"""
Step 7: Report Generator Module (ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±)
ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¦¬í¬íŠ¸ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import json
from datetime import datetime
import pandas as pd
import config


def generate_report(
    topic_info: dict,
    q_set: list[str],
    personas: list[dict],
    sorting_matrix: pd.DataFrame,
    factor_result: dict,
    types: list[dict],
    output_path: str = None
) -> str:
    """
    ì „ì²´ ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        topic_info: ì—°êµ¬ ì£¼ì œ ì •ë³´
        q_set: Q-Set ë¬¸í•­ ë¦¬ìŠ¤íŠ¸
        personas: í˜ë¥´ì†Œë‚˜ ë¦¬ìŠ¤íŠ¸
        sorting_matrix: Q-Sorting ë°ì´í„° ë§¤íŠ¸ë¦­ìŠ¤
        factor_result: ìš”ì¸ ë¶„ì„ ê²°ê³¼
        types: ìƒì„±ëœ ìœ í˜• ë¦¬ìŠ¤íŠ¸
        output_path: ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
    
    Returns:
        ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ
    """
    report = []
    
    # í—¤ë”
    report.append(f"""# Që°©ë²•ë¡  ì—°êµ¬ í†µì°° ë¦¬í¬íŠ¸

**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}

---

## 1. ì—°êµ¬ ê°œìš”

### ğŸ“Œ ì—°êµ¬ ì£¼ì œ
**{topic_info.get('final_topic', 'N/A')}**

| í•­ëª© | ë‚´ìš© |
|------|------|
| ì—°êµ¬ ì§ˆë¬¸ | {topic_info.get('research_question', 'N/A')} |
| ëŒ€ìƒ ì§‘ë‹¨ | {topic_info.get('target_population', 'N/A')} |
| ì—°êµ¬ ë§¥ë½ | {topic_info.get('context', 'N/A')} |
| í•µì‹¬ í‚¤ì›Œë“œ | {', '.join(topic_info.get('keywords', []))} |

---

## 2. Q-Set ë¬¸í•­ ({len(q_set)}ê°œ)

""")
    
    # Q-Set ë¬¸í•­ ëª©ë¡
    for i, stmt in enumerate(q_set):
        report.append(f"{i+1}. {stmt}")
    
    report.append(f"""

---

## 3. ì°¸ì—¬ì (P-Set) ì •ë³´ ({len(personas)}ëª…)

""")
    
    # í˜ë¥´ì†Œë‚˜ ìš”ì•½
    for i, p in enumerate(personas):
        report.append(f"""
### {i+1}. {p.get('name', f'ì°¸ì—¬ì {i+1}')}
- **í”„ë¡œí•„**: {p.get('age', '?')}ì„¸, {p.get('gender', '?')}, {p.get('occupation', '?')}
- **ì„±ê²© íŠ¹ì„±**: {', '.join(p.get('personality_traits', []))}
- **í•µì‹¬ ê°€ì¹˜ê´€**: {', '.join(p.get('values', []))}
- **ì£¼ì œ íƒœë„**: {p.get('attitude_toward_topic', 'N/A')[:100]}...
""")
    
    report.append(f"""

---

## 4. ìš”ì¸ ë¶„ì„ ê²°ê³¼

### ğŸ“Š ì¶”ì¶œëœ ìš”ì¸ ìˆ˜: {factor_result.get('n_factors', 'N/A')}

""")
    
    # ë¶„ì‚° ì„¤ëª…ë ¥
    variance = factor_result.get('variance', {})
    if variance:
        report.append("| ìš”ì¸ | Eigenvalue | ë¶„ì‚° ì„¤ëª…ë ¥ | ëˆ„ì  ë¶„ì‚° |")
        report.append("|------|------------|-------------|-----------|")
        for i in range(factor_result.get('n_factors', 0)):
            report.append(f"| Factor {i+1} | {variance['ss_loadings'][i]:.2f} | {variance['proportion_var'][i]:.1%} | {variance['cumulative_var'][i]:.1%} |")
    
    # ìš”ì¸ ì ì¬ëŸ‰ í‘œ
    loadings_df = factor_result.get('loadings_df')
    if loadings_df is not None:
        report.append("\n### ì°¸ì—¬ìë³„ ìš”ì¸ ì ì¬ëŸ‰\n")
        report.append(loadings_df.to_markdown())
    
    report.append(f"""

---

## 5. ë„ì¶œëœ ìœ í˜• ë¶„ì„ ({len(types)}ê°œ ìœ í˜•)

""")
    
    # ê° ìœ í˜• ìƒì„¸ ë¶„ì„
    for i, t in enumerate(types):
        bias_emoji = "ğŸ”µ" if t.get("bias") == "positive" else "ğŸ”´"
        bias_label = "ê¸ì • í¸í–¥" if t.get("bias") == "positive" else "ë¶€ì • í¸í–¥"
        
        # í•µì‹¬ ë¬¸í•­
        key_statements = t.get('key_statements', [])
        statements_text = ""
        for item in key_statements[:5]:
            score_sign = "+" if item['z_score'] > 0 else ""
            statements_text += f"   - {item['statement']} (Z: {score_sign}{item['z_score']:.2f})\n"
        
        report.append(f"""
### {bias_emoji} ìœ í˜• {i+1}: {t.get('type_name', f'ìœ í˜• {i+1}')}

> **{t.get('short_description', 'N/A')}**

| ì†ì„± | ì •ë³´ |
|------|------|
| ê¸°ë°˜ ìš”ì¸ | {t.get('factor', 'N/A')} |
| í¸í–¥ ë°©í–¥ | {bias_label} |

#### ğŸ“– ì‹¬ë¦¬ ë¶„ì„
{t.get('psychology_analysis', 'N/A')}

#### ğŸ¯ í•µì‹¬ ê°€ì¹˜
{', '.join(t.get('core_values', ['N/A']))}

#### ğŸ“‹ í–‰ë™ íŒ¨í„´
""")
        for pattern in t.get('behavioral_patterns', []):
            report.append(f"- {pattern}")
        
        report.append(f"""

#### ğŸ’ª ê°•ì 
""")
        for strength in t.get('strengths', []):
            report.append(f"- {strength}")
        
        report.append(f"""

#### âš ï¸ ë„ì „ ê³¼ì œ
""")
        for challenge in t.get('challenges', []):
            report.append(f"- {challenge}")
        
        report.append(f"""

#### ğŸ’¡ ì‹¤ìš©ì  ì¡°ì–¸
""")
        for advice in t.get('practical_advice', []):
            report.append(f"1. {advice}")
        
        report.append(f"""

#### ğŸš€ ê¶Œì¥ í–‰ë™
""")
        for action in t.get('recommended_actions', []):
            report.append(f"- {action}")
        
        report.append(f"""

#### ğŸ“Œ í•µì‹¬ ë¬¸í•­
{statements_text}

---
""")
    
    # ê²°ë¡  ë° ìš”ì•½
    report.append(f"""

## 6. ê²°ë¡  ë° ìš”ì•½

### ğŸ“Š ìœ í˜• ë¶„í¬ ìš”ì•½

| ìœ í˜•ëª… | ìš”ì¸ | í¸í–¥ | í•µì‹¬ íŠ¹ì§• |
|--------|------|------|----------|
""")
    
    for t in types:
        bias = "ê¸ì •" if t.get("bias") == "positive" else "ë¶€ì •"
        report.append(f"| {t.get('type_name', 'N/A')} | {t.get('factor', 'N/A')} | {bias} | {t.get('short_description', 'N/A')} |")
    
    report.append(f"""

### ğŸ” ì£¼ìš” í†µì°°

ë³¸ Që°©ë²•ë¡  ì—°êµ¬ë¥¼ í†µí•´ **{topic_info.get('final_topic', 'ì—°êµ¬ ì£¼ì œ')}**ì— ëŒ€í•œ ë‹¤ì–‘í•œ ê´€ì ì„ íƒìƒ‰í•˜ì˜€ìŠµë‹ˆë‹¤.

- **ì¶”ì¶œëœ ìš”ì¸ ìˆ˜**: {factor_result.get('n_factors', 0)}ê°œ
- **ë„ì¶œëœ ìœ í˜• ìˆ˜**: {len(types)}ê°œ (ìš”ì¸ë‹¹ ê¸ì •/ë¶€ì • 2ê°œì”©)
- **ë¶„ì„ ëŒ€ìƒ ë¬¸í•­**: {len(q_set)}ê°œ
- **ê°€ìƒ ì°¸ì—¬ì**: {len(personas)}ëª…

ê° ìœ í˜•ì€ ì—°êµ¬ ì£¼ì œì— ëŒ€í•œ ë…íŠ¹í•œ ì£¼ê´€ì  ê´€ì ì„ ë°˜ì˜í•˜ë©°, ì‹¤ë¬´ì—ì„œ íƒ€ê²Ÿ ì§‘ë‹¨ë³„ ë§ì¶¤í˜• ì „ëµ ìˆ˜ë¦½ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

*ì´ ë¦¬í¬íŠ¸ëŠ” Q-Methodology Research Insight Generatorì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
""")
    
    # íŒŒì¼ ì €ì¥
    report_content = "\n".join(report)
    
    if output_path is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"q_report_{timestamp}.md"
        output_path = os.path.join(config.OUTPUT_DIR, filename)
    
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"\nâœ… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {output_path}")
    
    return output_path


def save_data_artifacts(
    topic_info: dict,
    q_population: list[str],
    q_set: list[str],
    personas: list[dict],
    sorting_matrix: pd.DataFrame,
    output_dir: str = None
) -> dict:
    """
    ë¶„ì„ì— ì‚¬ìš©ëœ ë°ì´í„°ë¥¼ JSON/CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        topic_info: ì—°êµ¬ ì£¼ì œ ì •ë³´
        q_population: Q-Population ë¬¸í•­
        q_set: Q-Set ë¬¸í•­
        personas: í˜ë¥´ì†Œë‚˜
        sorting_matrix: Q-Sorting ë§¤íŠ¸ë¦­ìŠ¤
        output_dir: ì €ì¥ ë””ë ‰í† ë¦¬
    
    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬
    """
    if output_dir is None:
        output_dir = config.OUTPUT_DIR
    
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    paths = {}
    
    # ì—°êµ¬ ì£¼ì œ ì •ë³´
    topic_path = os.path.join(output_dir, f"topic_{timestamp}.json")
    with open(topic_path, 'w', encoding='utf-8') as f:
        json.dump(topic_info, f, ensure_ascii=False, indent=2)
    paths['topic'] = topic_path
    
    # Q-Population
    qpop_path = os.path.join(output_dir, f"q_population_{timestamp}.json")
    with open(qpop_path, 'w', encoding='utf-8') as f:
        json.dump(q_population, f, ensure_ascii=False, indent=2)
    paths['q_population'] = qpop_path
    
    # Q-Set
    qset_path = os.path.join(output_dir, f"q_set_{timestamp}.json")
    with open(qset_path, 'w', encoding='utf-8') as f:
        json.dump(q_set, f, ensure_ascii=False, indent=2)
    paths['q_set'] = qset_path
    
    # í˜ë¥´ì†Œë‚˜
    personas_path = os.path.join(output_dir, f"personas_{timestamp}.json")
    with open(personas_path, 'w', encoding='utf-8') as f:
        json.dump(personas, f, ensure_ascii=False, indent=2)
    paths['personas'] = personas_path
    
    # Q-Sorting ë§¤íŠ¸ë¦­ìŠ¤
    matrix_path = os.path.join(output_dir, f"sorting_matrix_{timestamp}.csv")
    sorting_matrix.to_csv(matrix_path, encoding='utf-8')
    paths['sorting_matrix'] = matrix_path
    
    print(f"\nğŸ“ ë°ì´í„° ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì™„ë£Œ: {output_dir}")
    
    return paths


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    test_topic = {
        "final_topic": "í…ŒìŠ¤íŠ¸ ì—°êµ¬ ì£¼ì œ",
        "research_question": "í…ŒìŠ¤íŠ¸ ì§ˆë¬¸",
        "target_population": "í…ŒìŠ¤íŠ¸ ëŒ€ìƒ",
        "context": "í…ŒìŠ¤íŠ¸ ë§¥ë½",
        "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
    }
    
    test_types = [
        {
            "factor": "Factor1",
            "bias": "positive",
            "type_name": "í…ŒìŠ¤íŠ¸ ìœ í˜•",
            "short_description": "í…ŒìŠ¤íŠ¸ ì„¤ëª…",
            "psychology_analysis": "ì‹¬ë¦¬ ë¶„ì„ ë‚´ìš©",
            "core_values": ["ê°€ì¹˜1", "ê°€ì¹˜2"],
            "behavioral_patterns": ["íŒ¨í„´1"],
            "strengths": ["ê°•ì 1"],
            "challenges": ["ë„ì „1"],
            "practical_advice": ["ì¡°ì–¸1"],
            "recommended_actions": ["í–‰ë™1"],
            "key_statements": [{"statement": "í…ŒìŠ¤íŠ¸ ë¬¸í•­", "z_score": 1.5}]
        }
    ]
    
    print("í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±...")
